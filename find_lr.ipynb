{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from model_multi_gpu import ModelMGPU\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "input_shape = (299, 299, 3)\n",
    "n_out = 28\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "tfconfig = tfconfig = tf.ConfigProto(\n",
    "                gpu_options=tf.GPUOptions(allow_growth=True)\n",
    "            )\n",
    "sess = tf.Session(config=tfconfig)\n",
    "K.set_session(sess)\n",
    "# create model\n",
    "model_name = 'resnet50'\n",
    "\n",
    "if model_name == 'xception':\n",
    "    from model.xception import MyXception\n",
    "    model = MyXception.create_model(\n",
    "        input_shape=input_shape,\n",
    "        n_out=n_out)\n",
    "elif model_name == 'resnet50':\n",
    "    from model.resnet50 import MyResNet50\n",
    "    model = MyResNet50.create_model(\n",
    "        input_shape=input_shape,\n",
    "        n_out=n_out)\n",
    "\n",
    "\n",
    "model = ModelMGPU(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_model.load_weights('./tflog/20181113015455-xception-adam-lr0.001-B64-s299-binary-brute-tta-znorm/xception.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data ...\n",
      "loading validation data ...\n"
     ]
    }
   ],
   "source": [
    "print('loading train data ...')\n",
    "x_train = np.load('./data/npy_data/x_train_rgb_{}.npy'.format(input_shape[0]))\n",
    "y_train = np.load('./data/npy_data/y_train_rgb_{}.npy'.format(input_shape[0]))\n",
    "print('loading validation data ...')\n",
    "x_valid = np.load('./data/npy_data/x_valid_rgb_{}.npy'.format(input_shape[0]))\n",
    "y_valid = np.load('./data/npy_data/y_valid_rgb_{}.npy'.format(input_shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24857 samples, validate on 6215 samples\n",
      "Epoch 1/1\n",
      "   64/24857 [..............................] - ETA: 1:48:34 - loss: 1.0432 - acc: 0.4967 - LRFinder: val_loss: 0.9913 - lr = 0.00000105 \n",
      "  128/24857 [..............................] - ETA: 1:17:01 - loss: 1.0398 - acc: 0.4944 - LRFinder: val_loss: 0.9702 - lr = 0.00000110 \n",
      "  192/24857 [..............................] - ETA: 1:02:19 - loss: 1.0469 - acc: 0.4931 - LRFinder: val_loss: 0.9343 - lr = 0.00000115 \n",
      "  256/24857 [..............................] - ETA: 54:48 - loss: 1.0219 - acc: 0.5054   - LRFinder: val_loss: 0.9104 - lr = 0.00000121 \n",
      "  320/24857 [..............................] - ETA: 50:23 - loss: 0.9997 - acc: 0.5167 - LRFinder: val_loss: 0.8893 - lr = 0.00000127 \n",
      "  384/24857 [..............................] - ETA: 47:16 - loss: 0.9766 - acc: 0.5266 - LRFinder: val_loss: 0.8557 - lr = 0.00000133 \n",
      "  448/24857 [..............................] - ETA: 45:02 - loss: 0.9638 - acc: 0.5314 - LRFinder: val_loss: 0.8251 - lr = 0.00000140 \n",
      "  512/24857 [..............................] - ETA: 43:22 - loss: 0.9450 - acc: 0.5408 - LRFinder: val_loss: 0.7869 - lr = 0.00000146 \n",
      "  576/24857 [..............................] - ETA: 42:04 - loss: 0.9272 - acc: 0.5492 - LRFinder: val_loss: 0.7578 - lr = 0.00000153 \n",
      "  640/24857 [..............................] - ETA: 41:02 - loss: 0.9079 - acc: 0.5580 - LRFinder: val_loss: 0.7178 - lr = 0.00000161 \n",
      "  704/24857 [..............................] - ETA: 40:11 - loss: 0.8906 - acc: 0.5677 - LRFinder: val_loss: 0.6864 - lr = 0.00000169 \n",
      "  768/24857 [..............................] - ETA: 39:29 - loss: 0.8753 - acc: 0.5747 - LRFinder: val_loss: 0.6541 - lr = 0.00000177 \n",
      "  832/24857 [>.............................] - ETA: 38:48 - loss: 0.8596 - acc: 0.5830 - LRFinder: val_loss: 0.6277 - lr = 0.00000186 \n",
      "  896/24857 [>.............................] - ETA: 38:16 - loss: 0.8421 - acc: 0.5916 - LRFinder: val_loss: 0.5983 - lr = 0.00000195 \n",
      "  960/24857 [>.............................] - ETA: 37:54 - loss: 0.8262 - acc: 0.6007 - LRFinder: val_loss: 0.5592 - lr = 0.00000204 \n",
      " 1024/24857 [>.............................] - ETA: 37:24 - loss: 0.8112 - acc: 0.6082 - LRFinder: val_loss: 0.5328 - lr = 0.00000214 \n",
      " 1088/24857 [>.............................] - ETA: 36:57 - loss: 0.7953 - acc: 0.6169 - LRFinder: val_loss: 0.5056 - lr = 0.00000225 \n",
      " 1152/24857 [>.............................] - ETA: 36:35 - loss: 0.7791 - acc: 0.6260 - LRFinder: val_loss: 0.4732 - lr = 0.00000236 \n",
      " 1216/24857 [>.............................] - ETA: 36:14 - loss: 0.7636 - acc: 0.6344 - LRFinder: val_loss: 0.4488 - lr = 0.00000247 \n",
      " 1280/24857 [>.............................] - ETA: 35:55 - loss: 0.7485 - acc: 0.6427 - LRFinder: val_loss: 0.4267 - lr = 0.00000259 \n",
      " 1344/24857 [>.............................] - ETA: 35:37 - loss: 0.7342 - acc: 0.6503 - LRFinder: val_loss: 0.4014 - lr = 0.00000272 \n",
      " 1408/24857 [>.............................] - ETA: 35:20 - loss: 0.7190 - acc: 0.6589 - LRFinder: val_loss: 0.3821 - lr = 0.00000285 \n",
      " 1472/24857 [>.............................] - ETA: 35:05 - loss: 0.7041 - acc: 0.6669 - LRFinder: val_loss: 0.3630 - lr = 0.00000299 \n",
      " 1536/24857 [>.............................] - ETA: 34:52 - loss: 0.6904 - acc: 0.6746 - LRFinder: val_loss: 0.3508 - lr = 0.00000313 \n",
      " 1600/24857 [>.............................] - ETA: 34:38 - loss: 0.6762 - acc: 0.6826 - LRFinder: val_loss: 0.3285 - lr = 0.00000329 \n",
      " 1664/24857 [=>............................] - ETA: 34:25 - loss: 0.6636 - acc: 0.6900 - LRFinder: val_loss: 0.3202 - lr = 0.00000345 \n",
      " 1728/24857 [=>............................] - ETA: 34:12 - loss: 0.6505 - acc: 0.6970 - LRFinder: val_loss: 0.3037 - lr = 0.00000362 \n",
      " 1792/24857 [=>............................] - ETA: 34:01 - loss: 0.6378 - acc: 0.7041 - LRFinder: val_loss: 0.2929 - lr = 0.00000379 \n",
      " 1856/24857 [=>............................] - ETA: 33:51 - loss: 0.6257 - acc: 0.7110 - LRFinder: val_loss: 0.2875 - lr = 0.00000398 \n",
      " 1920/24857 [=>............................] - ETA: 33:41 - loss: 0.6141 - acc: 0.7177 - LRFinder: val_loss: 0.2778 - lr = 0.00000417 \n",
      " 1984/24857 [=>............................] - ETA: 33:29 - loss: 0.6040 - acc: 0.7236 - LRFinder: val_loss: 0.2702 - lr = 0.00000437 \n",
      " 2048/24857 [=>............................] - ETA: 33:19 - loss: 0.5931 - acc: 0.7299 - LRFinder: val_loss: 0.2633 - lr = 0.00000459 \n",
      " 2112/24857 [=>............................] - ETA: 33:08 - loss: 0.5834 - acc: 0.7356 - LRFinder: val_loss: 0.2592 - lr = 0.00000481 \n",
      " 2176/24857 [=>............................] - ETA: 32:57 - loss: 0.5741 - acc: 0.7411 - LRFinder: val_loss: 0.2563 - lr = 0.00000504 \n",
      " 2240/24857 [=>............................] - ETA: 32:48 - loss: 0.5647 - acc: 0.7463 - LRFinder: val_loss: 0.2551 - lr = 0.00000529 \n",
      " 2304/24857 [=>............................] - ETA: 32:39 - loss: 0.5561 - acc: 0.7515 - LRFinder: val_loss: 0.2491 - lr = 0.00000555 \n",
      " 2368/24857 [=>............................] - ETA: 32:28 - loss: 0.5478 - acc: 0.7563 - LRFinder: val_loss: 0.2485 - lr = 0.00000582 \n",
      " 2432/24857 [=>............................] - ETA: 32:19 - loss: 0.5400 - acc: 0.7610 - LRFinder: val_loss: 0.2419 - lr = 0.00000610 \n",
      " 2496/24857 [==>...........................] - ETA: 32:10 - loss: 0.5327 - acc: 0.7653 - LRFinder: val_loss: 0.2465 - lr = 0.00000640 \n",
      " 2560/24857 [==>...........................] - ETA: 32:02 - loss: 0.5250 - acc: 0.7696 - LRFinder: val_loss: 0.2423 - lr = 0.00000671 \n",
      " 2624/24857 [==>...........................] - ETA: 31:53 - loss: 0.5179 - acc: 0.7737 - LRFinder: val_loss: 0.2304 - lr = 0.00000704 \n",
      " 2688/24857 [==>...........................] - ETA: 31:45 - loss: 0.5112 - acc: 0.7774 - LRFinder: val_loss: 0.2428 - lr = 0.00000738 \n",
      " 2752/24857 [==>...........................] - ETA: 31:36 - loss: 0.5048 - acc: 0.7811 - LRFinder: val_loss: 0.2369 - lr = 0.00000774 \n",
      " 2816/24857 [==>...........................] - ETA: 31:29 - loss: 0.4991 - acc: 0.7846 - LRFinder: val_loss: 0.2380 - lr = 0.00000812 \n",
      " 2880/24857 [==>...........................] - ETA: 31:20 - loss: 0.4936 - acc: 0.7879 - LRFinder: val_loss: 0.2372 - lr = 0.00000852 \n",
      " 2944/24857 [==>...........................] - ETA: 31:12 - loss: 0.4884 - acc: 0.7911 - LRFinder: val_loss: 0.2380 - lr = 0.00000893 \n",
      " 3008/24857 [==>...........................] - ETA: 31:05 - loss: 0.4839 - acc: 0.7939 - LRFinder: val_loss: 0.2314 - lr = 0.00000937 \n",
      " 3072/24857 [==>...........................] - ETA: 30:57 - loss: 0.4792 - acc: 0.7968 - LRFinder: val_loss: 0.2344 - lr = 0.00000982 \n",
      " 3136/24857 [==>...........................] - ETA: 30:49 - loss: 0.4744 - acc: 0.7996 - LRFinder: val_loss: 0.2342 - lr = 0.00001030 \n",
      " 3200/24857 [==>...........................] - ETA: 30:41 - loss: 0.4703 - acc: 0.8021 - LRFinder: val_loss: 0.2320 - lr = 0.00001080 \n",
      " 3264/24857 [==>...........................] - ETA: 30:34 - loss: 0.4651 - acc: 0.8049 - LRFinder: val_loss: 0.2279 - lr = 0.00001133 \n",
      " 3328/24857 [===>..........................] - ETA: 30:26 - loss: 0.4606 - acc: 0.8074 - LRFinder: val_loss: 0.2310 - lr = 0.00001188 \n",
      " 3392/24857 [===>..........................] - ETA: 30:19 - loss: 0.4566 - acc: 0.8098 - LRFinder: val_loss: 0.2326 - lr = 0.00001246 \n",
      " 3456/24857 [===>..........................] - ETA: 30:12 - loss: 0.4529 - acc: 0.8121 - LRFinder: val_loss: 0.2285 - lr = 0.00001307 \n",
      " 3520/24857 [===>..........................] - ETA: 30:05 - loss: 0.4485 - acc: 0.8144 - LRFinder: val_loss: 0.2240 - lr = 0.00001371 \n",
      " 3584/24857 [===>..........................] - ETA: 29:58 - loss: 0.4447 - acc: 0.8166 - LRFinder: val_loss: 0.2179 - lr = 0.00001438 \n",
      " 3648/24857 [===>..........................] - ETA: 29:51 - loss: 0.4409 - acc: 0.8187 - LRFinder: val_loss: 0.2228 - lr = 0.00001508 \n",
      " 3712/24857 [===>..........................] - ETA: 29:44 - loss: 0.4371 - acc: 0.8207 - LRFinder: val_loss: 0.2212 - lr = 0.00001581 \n",
      " 3776/24857 [===>..........................] - ETA: 29:37 - loss: 0.4336 - acc: 0.8226 - LRFinder: val_loss: 0.2232 - lr = 0.00001658 \n",
      " 3840/24857 [===>..........................] - ETA: 29:31 - loss: 0.4306 - acc: 0.8245 - LRFinder: val_loss: 0.2219 - lr = 0.00001739 \n",
      " 3904/24857 [===>..........................] - ETA: 29:24 - loss: 0.4267 - acc: 0.8264 - LRFinder: val_loss: 0.2227 - lr = 0.00001824 \n",
      " 3968/24857 [===>..........................] - ETA: 29:17 - loss: 0.4234 - acc: 0.8282 - LRFinder: val_loss: 0.2220 - lr = 0.00001913 \n",
      " 4032/24857 [===>..........................] - ETA: 29:10 - loss: 0.4204 - acc: 0.8298 - LRFinder: val_loss: 0.2260 - lr = 0.00002006 \n",
      " 4096/24857 [===>..........................] - ETA: 29:04 - loss: 0.4173 - acc: 0.8315 - LRFinder: val_loss: 0.2204 - lr = 0.00002104 \n",
      " 4160/24857 [====>.........................] - ETA: 28:57 - loss: 0.4141 - acc: 0.8331 - LRFinder: val_loss: 0.2226 - lr = 0.00002206 \n",
      " 4224/24857 [====>.........................] - ETA: 28:50 - loss: 0.4120 - acc: 0.8345 - LRFinder: val_loss: 0.2169 - lr = 0.00002314 \n",
      " 4288/24857 [====>.........................] - ETA: 28:44 - loss: 0.4089 - acc: 0.8360 - LRFinder: val_loss: 0.2157 - lr = 0.00002427 \n",
      " 4352/24857 [====>.........................] - ETA: 28:38 - loss: 0.4064 - acc: 0.8374 - LRFinder: val_loss: 0.2181 - lr = 0.00002545 \n",
      " 4416/24857 [====>.........................] - ETA: 28:31 - loss: 0.4034 - acc: 0.8389 - LRFinder: val_loss: 0.2171 - lr = 0.00002669 \n",
      " 4480/24857 [====>.........................] - ETA: 28:25 - loss: 0.4010 - acc: 0.8402 - LRFinder: val_loss: 0.2114 - lr = 0.00002799 \n",
      " 4544/24857 [====>.........................] - ETA: 28:19 - loss: 0.3983 - acc: 0.8415 - LRFinder: val_loss: 0.2115 - lr = 0.00002936 \n",
      " 4608/24857 [====>.........................] - ETA: 28:12 - loss: 0.3954 - acc: 0.8429 - LRFinder: val_loss: 0.2133 - lr = 0.00003079 \n",
      " 4672/24857 [====>.........................] - ETA: 28:06 - loss: 0.3929 - acc: 0.8442 - LRFinder: val_loss: 0.2091 - lr = 0.00003229 \n",
      " 4736/24857 [====>.........................] - ETA: 28:01 - loss: 0.3904 - acc: 0.8454 - LRFinder: val_loss: 0.2232 - lr = 0.00003386 \n",
      " 4800/24857 [====>.........................] - ETA: 27:55 - loss: 0.3879 - acc: 0.8467 - LRFinder: val_loss: 0.2129 - lr = 0.00003551 \n",
      " 4864/24857 [====>.........................] - ETA: 27:49 - loss: 0.3860 - acc: 0.8478 - LRFinder: val_loss: 0.2099 - lr = 0.00003724 \n",
      " 4928/24857 [====>.........................] - ETA: 27:43 - loss: 0.3836 - acc: 0.8489 - LRFinder: val_loss: 0.2126 - lr = 0.00003906 \n",
      " 4992/24857 [=====>........................] - ETA: 27:37 - loss: 0.3817 - acc: 0.8500 - LRFinder: val_loss: 0.2116 - lr = 0.00004096 \n",
      " 5056/24857 [=====>........................] - ETA: 27:31 - loss: 0.3796 - acc: 0.8510 - LRFinder: val_loss: 0.2134 - lr = 0.00004296 \n",
      " 5120/24857 [=====>........................] - ETA: 27:25 - loss: 0.3778 - acc: 0.8520 - LRFinder: val_loss: 0.2050 - lr = 0.00004506 \n",
      " 5184/24857 [=====>........................] - ETA: 27:19 - loss: 0.3759 - acc: 0.8530 - LRFinder: val_loss: 0.2050 - lr = 0.00004725 \n",
      " 5248/24857 [=====>........................] - ETA: 27:13 - loss: 0.3737 - acc: 0.8541 - LRFinder: val_loss: 0.2033 - lr = 0.00004956 \n",
      " 5312/24857 [=====>........................] - ETA: 27:07 - loss: 0.3723 - acc: 0.8549 - LRFinder: val_loss: 0.2036 - lr = 0.00005197 \n",
      " 5376/24857 [=====>........................] - ETA: 27:01 - loss: 0.3702 - acc: 0.8560 - LRFinder: val_loss: 0.2020 - lr = 0.00005450 \n",
      " 5440/24857 [=====>........................] - ETA: 26:55 - loss: 0.3683 - acc: 0.8569 - LRFinder: val_loss: 0.2038 - lr = 0.00005716 \n",
      " 5504/24857 [=====>........................] - ETA: 26:48 - loss: 0.3665 - acc: 0.8578 - LRFinder: val_loss: 0.2017 - lr = 0.00005995 \n",
      " 5568/24857 [=====>........................] - ETA: 26:42 - loss: 0.3644 - acc: 0.8587 - LRFinder: val_loss: 0.1992 - lr = 0.00006287 \n",
      " 5632/24857 [=====>........................] - ETA: 26:36 - loss: 0.3628 - acc: 0.8596 - LRFinder: val_loss: 0.2076 - lr = 0.00006594 \n",
      " 5696/24857 [=====>........................] - ETA: 26:31 - loss: 0.3614 - acc: 0.8604 - LRFinder: val_loss: 0.2005 - lr = 0.00006915 \n",
      " 5760/24857 [=====>........................] - ETA: 26:26 - loss: 0.3594 - acc: 0.8613 - LRFinder: val_loss: 0.2006 - lr = 0.00007252 \n",
      " 5824/24857 [======>.......................] - ETA: 26:20 - loss: 0.3578 - acc: 0.8621 - LRFinder: val_loss: 0.1980 - lr = 0.00007606 \n",
      " 5888/24857 [======>.......................] - ETA: 26:13 - loss: 0.3563 - acc: 0.8630 - LRFinder: val_loss: 0.2024 - lr = 0.00007976 \n",
      " 5952/24857 [======>.......................] - ETA: 26:08 - loss: 0.3547 - acc: 0.8638 - LRFinder: val_loss: 0.2046 - lr = 0.00008365 \n",
      " 6016/24857 [======>.......................] - ETA: 26:02 - loss: 0.3532 - acc: 0.8646 - LRFinder: val_loss: 0.1956 - lr = 0.00008773 \n",
      " 6080/24857 [======>.......................] - ETA: 25:57 - loss: 0.3516 - acc: 0.8653 - LRFinder: val_loss: 0.2058 - lr = 0.00009201 \n",
      " 6144/24857 [======>.......................] - ETA: 25:51 - loss: 0.3502 - acc: 0.8660 - LRFinder: val_loss: 0.2097 - lr = 0.00009649 \n",
      " 6208/24857 [======>.......................] - ETA: 25:45 - loss: 0.3489 - acc: 0.8666 - LRFinder: val_loss: 0.2012 - lr = 0.00010120 \n",
      " 6272/24857 [======>.......................] - ETA: 25:39 - loss: 0.3473 - acc: 0.8673 - LRFinder: val_loss: 0.2006 - lr = 0.00010613 \n",
      " 6336/24857 [======>.......................] - ETA: 25:33 - loss: 0.3460 - acc: 0.8679 - LRFinder: val_loss: 0.1970 - lr = 0.00011130 \n",
      " 6400/24857 [======>.......................] - ETA: 25:27 - loss: 0.3445 - acc: 0.8687 - LRFinder: val_loss: 0.2009 - lr = 0.00011673 \n",
      " 6464/24857 [======>.......................] - ETA: 25:22 - loss: 0.3430 - acc: 0.8694 - LRFinder: val_loss: 0.1941 - lr = 0.00012242 \n",
      " 6528/24857 [======>.......................] - ETA: 25:16 - loss: 0.3417 - acc: 0.8701 - LRFinder: val_loss: 0.2028 - lr = 0.00012839 \n",
      " 6592/24857 [======>.......................] - ETA: 25:11 - loss: 0.3405 - acc: 0.8707 - LRFinder: val_loss: 0.1982 - lr = 0.00013465 \n",
      " 6656/24857 [=======>......................] - ETA: 25:05 - loss: 0.3390 - acc: 0.8714 - LRFinder: val_loss: 0.2070 - lr = 0.00014121 \n",
      " 6720/24857 [=======>......................] - ETA: 24:59 - loss: 0.3378 - acc: 0.8721 - LRFinder: val_loss: 0.2043 - lr = 0.00014810 \n",
      " 6784/24857 [=======>......................] - ETA: 24:54 - loss: 0.3365 - acc: 0.8727 - LRFinder: val_loss: 0.1936 - lr = 0.00015532 \n",
      " 6848/24857 [=======>......................] - ETA: 24:48 - loss: 0.3352 - acc: 0.8734 - LRFinder: val_loss: 0.1971 - lr = 0.00016289 \n",
      " 6912/24857 [=======>......................] - ETA: 24:42 - loss: 0.3342 - acc: 0.8739 - LRFinder: val_loss: 0.1965 - lr = 0.00017083 \n",
      " 6976/24857 [=======>......................] - ETA: 24:36 - loss: 0.3329 - acc: 0.8745 - LRFinder: val_loss: 0.1974 - lr = 0.00017916 \n",
      " 7040/24857 [=======>......................] - ETA: 24:31 - loss: 0.3318 - acc: 0.8751 - LRFinder: val_loss: 0.2050 - lr = 0.00018789 \n",
      " 7104/24857 [=======>......................] - ETA: 24:25 - loss: 0.3306 - acc: 0.8757 - LRFinder: val_loss: 0.2101 - lr = 0.00019705 \n",
      " 7168/24857 [=======>......................] - ETA: 24:19 - loss: 0.3295 - acc: 0.8762 - LRFinder: val_loss: 0.2102 - lr = 0.00020665 \n",
      " 7232/24857 [=======>......................] - ETA: 24:14 - loss: 0.3285 - acc: 0.8768 - LRFinder: val_loss: 0.2150 - lr = 0.00021673 \n",
      " 7296/24857 [=======>......................] - ETA: 24:08 - loss: 0.3273 - acc: 0.8773 - LRFinder: val_loss: 0.2169 - lr = 0.00022729 \n",
      " 7360/24857 [=======>......................] - ETA: 24:03 - loss: 0.3264 - acc: 0.8779 - LRFinder: val_loss: 0.2034 - lr = 0.00023838 \n",
      " 7424/24857 [=======>......................] - ETA: 23:58 - loss: 0.3255 - acc: 0.8783 - LRFinder: val_loss: 0.2063 - lr = 0.00025000 \n",
      " 7488/24857 [========>.....................] - ETA: 23:52 - loss: 0.3244 - acc: 0.8788 - LRFinder: val_loss: 0.2342 - lr = 0.00026218 \n",
      " 7552/24857 [========>.....................] - ETA: 23:46 - loss: 0.3236 - acc: 0.8794 - LRFinder: val_loss: 0.2416 - lr = 0.00027496 \n",
      " 7616/24857 [========>.....................] - ETA: 23:41 - loss: 0.3225 - acc: 0.8799 - LRFinder: val_loss: 0.2351 - lr = 0.00028837 \n",
      " 7680/24857 [========>.....................] - ETA: 23:35 - loss: 0.3214 - acc: 0.8805 - LRFinder: val_loss: 0.2446 - lr = 0.00030243 \n",
      " 7744/24857 [========>.....................] - ETA: 23:29 - loss: 0.3205 - acc: 0.8810 - LRFinder: val_loss: 0.3075 - lr = 0.00031717 \n",
      " 7808/24857 [========>.....................] - ETA: 23:24 - loss: 0.3196 - acc: 0.8814 - LRFinder: val_loss: 0.3399 - lr = 0.00033263 \n",
      " 7872/24857 [========>.....................] - ETA: 23:18 - loss: 0.3185 - acc: 0.8819 - LRFinder: val_loss: 0.3118 - lr = 0.00034885 \n",
      " 7936/24857 [========>.....................] - ETA: 23:13 - loss: 0.3175 - acc: 0.8824 - LRFinder: val_loss: 0.2781 - lr = 0.00036585 \n",
      " 8000/24857 [========>.....................] - ETA: 23:07 - loss: 0.3166 - acc: 0.8829 - LRFinder: val_loss: 0.3231 - lr = 0.00038369 \n",
      " 8064/24857 [========>.....................] - ETA: 23:01 - loss: 0.3153 - acc: 0.8834 - LRFinder: val_loss: 0.3329 - lr = 0.00040239 \n",
      " 8128/24857 [========>.....................] - ETA: 22:56 - loss: 0.3144 - acc: 0.8839 - LRFinder: val_loss: 0.3430 - lr = 0.00042201 \n",
      " 8192/24857 [========>.....................] - ETA: 22:51 - loss: 0.3136 - acc: 0.8843 - LRFinder: val_loss: 0.3440 - lr = 0.00044258 \n",
      " 8256/24857 [========>.....................] - ETA: 22:45 - loss: 0.3128 - acc: 0.8847 - LRFinder: val_loss: 0.3810 - lr = 0.00046416 \n",
      " 8320/24857 [=========>....................] - ETA: 22:40 - loss: 0.3118 - acc: 0.8852 - LRFinder: val_loss: 0.3666 - lr = 0.00048679 \n",
      " 8384/24857 [=========>....................] - ETA: 22:34 - loss: 0.3108 - acc: 0.8856 - LRFinder: val_loss: 0.2556 - lr = 0.00051052 \n",
      " 8448/24857 [=========>....................] - ETA: 22:29 - loss: 0.3099 - acc: 0.8861 - LRFinder: val_loss: 0.3048 - lr = 0.00053540 \n",
      " 8512/24857 [=========>....................] - ETA: 22:24 - loss: 0.3090 - acc: 0.8865 - LRFinder: val_loss: 0.2917 - lr = 0.00056151 \n",
      " 8576/24857 [=========>....................] - ETA: 22:18 - loss: 0.3081 - acc: 0.8869 - LRFinder: val_loss: 0.3067 - lr = 0.00058888 \n",
      " 8640/24857 [=========>....................] - ETA: 22:13 - loss: 0.3073 - acc: 0.8873 - LRFinder: val_loss: 0.2543 - lr = 0.00061759 \n",
      " 8704/24857 [=========>....................] - ETA: 22:07 - loss: 0.3064 - acc: 0.8877 - LRFinder: val_loss: 0.2386 - lr = 0.00064769 \n",
      " 8768/24857 [=========>....................] - ETA: 22:02 - loss: 0.3053 - acc: 0.8881 - LRFinder: val_loss: 0.2230 - lr = 0.00067927 \n",
      " 8832/24857 [=========>....................] - ETA: 21:56 - loss: 0.3044 - acc: 0.8885 - LRFinder: val_loss: 0.2385 - lr = 0.00071238 \n",
      " 8896/24857 [=========>....................] - ETA: 21:51 - loss: 0.3035 - acc: 0.8889 - LRFinder: val_loss: 0.2271 - lr = 0.00074711 \n",
      " 8960/24857 [=========>....................] - ETA: 21:45 - loss: 0.3024 - acc: 0.8893 - LRFinder: val_loss: 0.2390 - lr = 0.00078353 \n",
      " 9024/24857 [=========>....................] - ETA: 21:40 - loss: 0.3014 - acc: 0.8898 - LRFinder: val_loss: 0.2665 - lr = 0.00082173 \n",
      " 9088/24857 [=========>....................] - ETA: 21:34 - loss: 0.3006 - acc: 0.8902 - LRFinder: val_loss: 0.2630 - lr = 0.00086179 \n",
      " 9152/24857 [==========>...................] - ETA: 21:29 - loss: 0.2998 - acc: 0.8905 - LRFinder: val_loss: 0.2535 - lr = 0.00090380 \n",
      " 9216/24857 [==========>...................] - ETA: 21:23 - loss: 0.2989 - acc: 0.8909 - LRFinder: val_loss: 0.2943 - lr = 0.00094786 \n",
      " 9280/24857 [==========>...................] - ETA: 21:18 - loss: 0.2982 - acc: 0.8913 - LRFinder: val_loss: 0.2746 - lr = 0.00099407 \n",
      " 9344/24857 [==========>...................] - ETA: 21:12 - loss: 0.2973 - acc: 0.8916 - LRFinder: val_loss: 0.3145 - lr = 0.00104253 \n",
      " 9408/24857 [==========>...................] - ETA: 21:07 - loss: 0.2966 - acc: 0.8920 - LRFinder: val_loss: 0.3206 - lr = 0.00109335 \n",
      " 9472/24857 [==========>...................] - ETA: 21:02 - loss: 0.2959 - acc: 0.8923 - LRFinder: val_loss: 0.2912 - lr = 0.00114665 \n",
      " 9536/24857 [==========>...................] - ETA: 20:57 - loss: 0.2951 - acc: 0.8926 - LRFinder: val_loss: 0.2345 - lr = 0.00120255 \n",
      " 9600/24857 [==========>...................] - ETA: 20:52 - loss: 0.2942 - acc: 0.8930 - LRFinder: val_loss: 0.2139 - lr = 0.00126118 \n",
      " 9664/24857 [==========>...................] - ETA: 20:47 - loss: 0.2933 - acc: 0.8933 - LRFinder: val_loss: 0.1956 - lr = 0.00132266 \n",
      " 9728/24857 [==========>...................] - ETA: 20:41 - loss: 0.2924 - acc: 0.8937 - LRFinder: val_loss: 0.2002 - lr = 0.00138714 \n",
      " 9792/24857 [==========>...................] - ETA: 20:36 - loss: 0.2917 - acc: 0.8940 - LRFinder: val_loss: 0.1892 - lr = 0.00145476 \n",
      " 9856/24857 [==========>...................] - ETA: 20:30 - loss: 0.2910 - acc: 0.8943 - LRFinder: val_loss: 0.1909 - lr = 0.00152568 \n",
      " 9920/24857 [==========>...................] - ETA: 20:25 - loss: 0.2901 - acc: 0.8947 - LRFinder: val_loss: 0.1830 - lr = 0.00160005 \n",
      " 9984/24857 [===========>..................] - ETA: 20:19 - loss: 0.2893 - acc: 0.8951 - LRFinder: val_loss: 0.1817 - lr = 0.00167806 \n",
      "10048/24857 [===========>..................] - ETA: 20:14 - loss: 0.2884 - acc: 0.8955 - LRFinder: val_loss: 0.1974 - lr = 0.00175986 \n",
      "10112/24857 [===========>..................] - ETA: 20:09 - loss: 0.2876 - acc: 0.8958 - LRFinder: val_loss: 0.1966 - lr = 0.00184565 \n",
      "10176/24857 [===========>..................] - ETA: 20:03 - loss: 0.2870 - acc: 0.8961 - LRFinder: val_loss: 0.1993 - lr = 0.00193563 \n",
      "10240/24857 [===========>..................] - ETA: 19:58 - loss: 0.2862 - acc: 0.8964 - LRFinder: val_loss: 0.1923 - lr = 0.00202999 \n",
      "10304/24857 [===========>..................] - ETA: 19:52 - loss: 0.2855 - acc: 0.8967 - LRFinder: val_loss: 0.1945 - lr = 0.00212895 \n",
      "10368/24857 [===========>..................] - ETA: 19:47 - loss: 0.2848 - acc: 0.8971 - LRFinder: val_loss: 0.2065 - lr = 0.00223274 \n",
      "10432/24857 [===========>..................] - ETA: 19:41 - loss: 0.2842 - acc: 0.8973 - LRFinder: val_loss: 0.2275 - lr = 0.00234158 \n",
      "10496/24857 [===========>..................] - ETA: 19:36 - loss: 0.2837 - acc: 0.8976 - LRFinder: val_loss: 0.2610 - lr = 0.00245573 \n",
      "10560/24857 [===========>..................] - ETA: 19:30 - loss: 0.2831 - acc: 0.8979 - LRFinder: val_loss: 0.4092 - lr = 0.00257545 \n",
      "10624/24857 [===========>..................] - ETA: 19:25 - loss: 0.2827 - acc: 0.8981 - LRFinder: val_loss: 0.6605 - lr = 0.00270100 \n",
      "10688/24857 [===========>..................] - ETA: 19:20 - loss: 0.2822 - acc: 0.8983 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "10752/24857 [===========>..................] - ETA: 19:14 - loss: 0.2815 - acc: 0.8986 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "10816/24857 [============>.................] - ETA: 19:09 - loss: 0.2809 - acc: 0.8989 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "10880/24857 [============>.................] - ETA: 19:04 - loss: 0.2802 - acc: 0.8992 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "10944/24857 [============>.................] - ETA: 18:58 - loss: 0.2796 - acc: 0.8995 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11008/24857 [============>.................] - ETA: 18:53 - loss: 0.2789 - acc: 0.8998 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11072/24857 [============>.................] - ETA: 18:48 - loss: 0.2783 - acc: 0.9000 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11136/24857 [============>.................] - ETA: 18:42 - loss: 0.2778 - acc: 0.9002 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11200/24857 [============>.................] - ETA: 18:37 - loss: 0.2772 - acc: 0.9005 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11264/24857 [============>.................] - ETA: 18:32 - loss: 0.2766 - acc: 0.9007 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11328/24857 [============>.................] - ETA: 18:26 - loss: 0.2760 - acc: 0.9010 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11392/24857 [============>.................] - ETA: 18:21 - loss: 0.2755 - acc: 0.9012 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11456/24857 [============>.................] - ETA: 18:16 - loss: 0.2749 - acc: 0.9015 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11520/24857 [============>.................] - ETA: 18:10 - loss: 0.2743 - acc: 0.9017 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11584/24857 [============>.................] - ETA: 18:05 - loss: 0.2738 - acc: 0.9020 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11648/24857 [=============>................] - ETA: 18:00 - loss: 0.2733 - acc: 0.9022 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11712/24857 [=============>................] - ETA: 17:54 - loss: 0.2727 - acc: 0.9025 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11776/24857 [=============>................] - ETA: 17:49 - loss: 0.2722 - acc: 0.9027 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11840/24857 [=============>................] - ETA: 17:44 - loss: 0.2716 - acc: 0.9029 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11904/24857 [=============>................] - ETA: 17:38 - loss: 0.2711 - acc: 0.9031 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "11968/24857 [=============>................] - ETA: 17:33 - loss: 0.2704 - acc: 0.9034 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12032/24857 [=============>................] - ETA: 17:28 - loss: 0.2697 - acc: 0.9036 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12096/24857 [=============>................] - ETA: 17:22 - loss: 0.2693 - acc: 0.9038 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12160/24857 [=============>................] - ETA: 17:17 - loss: 0.2688 - acc: 0.9040 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12224/24857 [=============>................] - ETA: 17:12 - loss: 0.2682 - acc: 0.9043 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12288/24857 [=============>................] - ETA: 17:07 - loss: 0.2678 - acc: 0.9044 - LRFinder: val_loss: 0.6885 - lr = 0.00283267 \n",
      "12352/24857 [=============>................] - ETA: 17:02 - loss: 0.2673 - acc: 0.9046 - LRFinder: val_loss: 0.7168 - lr = 0.00297077 \n",
      "12416/24857 [=============>................] - ETA: 16:56 - loss: 0.2668 - acc: 0.9049 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12480/24857 [==============>...............] - ETA: 16:51 - loss: 0.2661 - acc: 0.9051 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12544/24857 [==============>...............] - ETA: 16:46 - loss: 0.2655 - acc: 0.9053 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12608/24857 [==============>...............] - ETA: 16:40 - loss: 0.2650 - acc: 0.9056 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12672/24857 [==============>...............] - ETA: 16:35 - loss: 0.2645 - acc: 0.9058 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12736/24857 [==============>...............] - ETA: 16:30 - loss: 0.2640 - acc: 0.9060 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12800/24857 [==============>...............] - ETA: 16:24 - loss: 0.2635 - acc: 0.9062 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12864/24857 [==============>...............] - ETA: 16:19 - loss: 0.2629 - acc: 0.9065 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12928/24857 [==============>...............] - ETA: 16:14 - loss: 0.2624 - acc: 0.9067 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "12992/24857 [==============>...............] - ETA: 16:08 - loss: 0.2618 - acc: 0.9069 - LRFinder: val_loss: 0.6768 - lr = 0.00311559 \n",
      "13056/24857 [==============>...............] - ETA: 16:03 - loss: 0.2613 - acc: 0.9071 - LRFinder: val_loss: 0.5888 - lr = 0.00326747 \n",
      "13120/24857 [==============>...............] - ETA: 15:58 - loss: 0.2607 - acc: 0.9073 - LRFinder: val_loss: 0.4459 - lr = 0.00342676 \n",
      "13184/24857 [==============>...............] - ETA: 15:53 - loss: 0.2602 - acc: 0.9076 - LRFinder: val_loss: 0.4121 - lr = 0.00359382 \n",
      "13248/24857 [==============>...............] - ETA: 15:47 - loss: 0.2597 - acc: 0.9077 - LRFinder: val_loss: 0.4007 - lr = 0.00376901 \n",
      "13312/24857 [===============>..............] - ETA: 15:42 - loss: 0.2592 - acc: 0.9079 - LRFinder: val_loss: 0.4149 - lr = 0.00395275 \n",
      "13376/24857 [===============>..............] - ETA: 15:37 - loss: 0.2588 - acc: 0.9081 - LRFinder: val_loss: 0.4554 - lr = 0.00414545 \n",
      "13440/24857 [===============>..............] - ETA: 15:32 - loss: 0.2583 - acc: 0.9083 - LRFinder: val_loss: 0.5157 - lr = 0.00434754 \n",
      "13504/24857 [===============>..............] - ETA: 15:26 - loss: 0.2577 - acc: 0.9085 - LRFinder: val_loss: 0.4278 - lr = 0.00455948 \n",
      "13568/24857 [===============>..............] - ETA: 15:21 - loss: 0.2573 - acc: 0.9087 - LRFinder: val_loss: 0.4400 - lr = 0.00478175 \n",
      "13632/24857 [===============>..............] - ETA: 15:16 - loss: 0.2568 - acc: 0.9089 - LRFinder: val_loss: 0.3595 - lr = 0.00501486 \n",
      "13696/24857 [===============>..............] - ETA: 15:11 - loss: 0.2564 - acc: 0.9091 - LRFinder: val_loss: 0.3733 - lr = 0.00525933 \n",
      "13760/24857 [===============>..............] - ETA: 15:05 - loss: 0.2560 - acc: 0.9092 - LRFinder: val_loss: 0.4857 - lr = 0.00551572 \n",
      "13824/24857 [===============>..............] - ETA: 15:00 - loss: 0.2557 - acc: 0.9094 - LRFinder: val_loss: 0.5296 - lr = 0.00578461 \n",
      "13888/24857 [===============>..............] - ETA: 14:55 - loss: 0.2553 - acc: 0.9095 - LRFinder: val_loss: 0.5669 - lr = 0.00606661 \n",
      "13952/24857 [===============>..............] - ETA: 14:49 - loss: 0.2549 - acc: 0.9097 - LRFinder: val_loss: 0.4284 - lr = 0.00636235 \n",
      "14016/24857 [===============>..............] - ETA: 14:44 - loss: 0.2545 - acc: 0.9099 - LRFinder: val_loss: 0.4245 - lr = 0.00667252 \n",
      "14080/24857 [===============>..............] - ETA: 14:39 - loss: 0.2541 - acc: 0.9100 - LRFinder: val_loss: 0.6176 - lr = 0.00699780 \n",
      "14144/24857 [================>.............] - ETA: 14:34 - loss: 0.2537 - acc: 0.9102 - LRFinder: val_loss: 0.5056 - lr = 0.00733894 \n",
      "14208/24857 [================>.............] - ETA: 14:29 - loss: 0.2534 - acc: 0.9103 - LRFinder: val_loss: 0.6466 - lr = 0.00769671 \n",
      "14272/24857 [================>.............] - ETA: 14:23 - loss: 0.2530 - acc: 0.9104 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14336/24857 [================>.............] - ETA: 14:18 - loss: 0.2527 - acc: 0.9106 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14400/24857 [================>.............] - ETA: 14:13 - loss: 0.2523 - acc: 0.9107 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14464/24857 [================>.............] - ETA: 14:07 - loss: 0.2519 - acc: 0.9109 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14528/24857 [================>.............] - ETA: 14:02 - loss: 0.2516 - acc: 0.9110 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14592/24857 [================>.............] - ETA: 13:57 - loss: 0.2512 - acc: 0.9112 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14656/24857 [================>.............] - ETA: 13:52 - loss: 0.2509 - acc: 0.9113 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14720/24857 [================>.............] - ETA: 13:46 - loss: 0.2505 - acc: 0.9115 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14784/24857 [================>.............] - ETA: 13:41 - loss: 0.2502 - acc: 0.9116 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14848/24857 [================>.............] - ETA: 13:36 - loss: 0.2500 - acc: 0.9117 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14912/24857 [================>.............] - ETA: 13:31 - loss: 0.2496 - acc: 0.9119 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "14976/24857 [=================>............] - ETA: 13:25 - loss: 0.2493 - acc: 0.9120 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15040/24857 [=================>............] - ETA: 13:20 - loss: 0.2490 - acc: 0.9122 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15104/24857 [=================>............] - ETA: 13:15 - loss: 0.2486 - acc: 0.9123 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15168/24857 [=================>............] - ETA: 13:10 - loss: 0.2483 - acc: 0.9125 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15232/24857 [=================>............] - ETA: 13:04 - loss: 0.2480 - acc: 0.9126 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15296/24857 [=================>............] - ETA: 12:59 - loss: 0.2477 - acc: 0.9127 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15360/24857 [=================>............] - ETA: 12:54 - loss: 0.2474 - acc: 0.9129 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15424/24857 [=================>............] - ETA: 12:49 - loss: 0.2471 - acc: 0.9130 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15488/24857 [=================>............] - ETA: 12:43 - loss: 0.2469 - acc: 0.9131 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15552/24857 [=================>............] - ETA: 12:38 - loss: 0.2465 - acc: 0.9132 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15616/24857 [=================>............] - ETA: 12:33 - loss: 0.2462 - acc: 0.9134 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15680/24857 [=================>............] - ETA: 12:28 - loss: 0.2459 - acc: 0.9135 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15744/24857 [==================>...........] - ETA: 12:22 - loss: 0.2456 - acc: 0.9136 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15808/24857 [==================>...........] - ETA: 12:17 - loss: 0.2453 - acc: 0.9138 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15872/24857 [==================>...........] - ETA: 12:12 - loss: 0.2450 - acc: 0.9139 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "15936/24857 [==================>...........] - ETA: 12:07 - loss: 0.2447 - acc: 0.9140 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16000/24857 [==================>...........] - ETA: 12:01 - loss: 0.2444 - acc: 0.9141 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16064/24857 [==================>...........] - ETA: 11:56 - loss: 0.2442 - acc: 0.9142 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16128/24857 [==================>...........] - ETA: 11:51 - loss: 0.2438 - acc: 0.9143 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16192/24857 [==================>...........] - ETA: 11:46 - loss: 0.2434 - acc: 0.9145 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16256/24857 [==================>...........] - ETA: 11:40 - loss: 0.2432 - acc: 0.9146 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16320/24857 [==================>...........] - ETA: 11:35 - loss: 0.2429 - acc: 0.9147 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16384/24857 [==================>...........] - ETA: 11:30 - loss: 0.2426 - acc: 0.9149 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16448/24857 [==================>...........] - ETA: 11:25 - loss: 0.2424 - acc: 0.9150 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16512/24857 [==================>...........] - ETA: 11:19 - loss: 0.2420 - acc: 0.9151 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16576/24857 [===================>..........] - ETA: 11:14 - loss: 0.2417 - acc: 0.9152 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16640/24857 [===================>..........] - ETA: 11:09 - loss: 0.2415 - acc: 0.9153 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16704/24857 [===================>..........] - ETA: 11:04 - loss: 0.2411 - acc: 0.9155 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16768/24857 [===================>..........] - ETA: 10:58 - loss: 0.2409 - acc: 0.9156 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16832/24857 [===================>..........] - ETA: 10:53 - loss: 0.2405 - acc: 0.9157 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16896/24857 [===================>..........] - ETA: 10:48 - loss: 0.2402 - acc: 0.9159 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "16960/24857 [===================>..........] - ETA: 10:43 - loss: 0.2399 - acc: 0.9160 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17024/24857 [===================>..........] - ETA: 10:37 - loss: 0.2396 - acc: 0.9161 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17088/24857 [===================>..........] - ETA: 10:32 - loss: 0.2393 - acc: 0.9162 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17152/24857 [===================>..........] - ETA: 10:27 - loss: 0.2390 - acc: 0.9163 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17216/24857 [===================>..........] - ETA: 10:22 - loss: 0.2387 - acc: 0.9164 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17280/24857 [===================>..........] - ETA: 10:17 - loss: 0.2384 - acc: 0.9166 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17344/24857 [===================>..........] - ETA: 10:12 - loss: 0.2380 - acc: 0.9167 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17408/24857 [====================>.........] - ETA: 10:06 - loss: 0.2377 - acc: 0.9169 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17472/24857 [====================>.........] - ETA: 10:01 - loss: 0.2374 - acc: 0.9170 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17536/24857 [====================>.........] - ETA: 9:56 - loss: 0.2371 - acc: 0.9171  - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17600/24857 [====================>.........] - ETA: 9:51 - loss: 0.2368 - acc: 0.9172 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17664/24857 [====================>.........] - ETA: 9:45 - loss: 0.2366 - acc: 0.9173 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17728/24857 [====================>.........] - ETA: 9:40 - loss: 0.2363 - acc: 0.9174 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17792/24857 [====================>.........] - ETA: 9:35 - loss: 0.2360 - acc: 0.9175 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17856/24857 [====================>.........] - ETA: 9:30 - loss: 0.2358 - acc: 0.9176 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17920/24857 [====================>.........] - ETA: 9:24 - loss: 0.2356 - acc: 0.9177 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "17984/24857 [====================>.........] - ETA: 9:19 - loss: 0.2353 - acc: 0.9178 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18048/24857 [====================>.........] - ETA: 9:14 - loss: 0.2349 - acc: 0.9180 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18112/24857 [====================>.........] - ETA: 9:09 - loss: 0.2346 - acc: 0.9181 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18176/24857 [====================>.........] - ETA: 9:03 - loss: 0.2343 - acc: 0.9182 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18240/24857 [=====================>........] - ETA: 8:58 - loss: 0.2340 - acc: 0.9183 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18304/24857 [=====================>........] - ETA: 8:53 - loss: 0.2337 - acc: 0.9185 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18368/24857 [=====================>........] - ETA: 8:48 - loss: 0.2334 - acc: 0.9186 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18432/24857 [=====================>........] - ETA: 8:42 - loss: 0.2331 - acc: 0.9187 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18496/24857 [=====================>........] - ETA: 8:37 - loss: 0.2328 - acc: 0.9188 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18560/24857 [=====================>........] - ETA: 8:32 - loss: 0.2324 - acc: 0.9189 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18624/24857 [=====================>........] - ETA: 8:27 - loss: 0.2322 - acc: 0.9190 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18688/24857 [=====================>........] - ETA: 8:21 - loss: 0.2320 - acc: 0.9191 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18752/24857 [=====================>........] - ETA: 8:16 - loss: 0.2317 - acc: 0.9192 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18816/24857 [=====================>........] - ETA: 8:11 - loss: 0.2315 - acc: 0.9193 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18880/24857 [=====================>........] - ETA: 8:06 - loss: 0.2313 - acc: 0.9194 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "18944/24857 [=====================>........] - ETA: 8:01 - loss: 0.2310 - acc: 0.9195 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19008/24857 [=====================>........] - ETA: 7:55 - loss: 0.2308 - acc: 0.9196 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19072/24857 [======================>.......] - ETA: 7:50 - loss: 0.2305 - acc: 0.9197 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19136/24857 [======================>.......] - ETA: 7:45 - loss: 0.2302 - acc: 0.9198 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19200/24857 [======================>.......] - ETA: 7:40 - loss: 0.2300 - acc: 0.9198 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19264/24857 [======================>.......] - ETA: 7:34 - loss: 0.2298 - acc: 0.9199 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19328/24857 [======================>.......] - ETA: 7:29 - loss: 0.2295 - acc: 0.9201 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19392/24857 [======================>.......] - ETA: 7:24 - loss: 0.2295 - acc: 0.9201 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19456/24857 [======================>.......] - ETA: 7:19 - loss: 0.2292 - acc: 0.9202 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19520/24857 [======================>.......] - ETA: 7:14 - loss: 0.2291 - acc: 0.9203 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19584/24857 [======================>.......] - ETA: 7:08 - loss: 0.2288 - acc: 0.9204 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19648/24857 [======================>.......] - ETA: 7:03 - loss: 0.2286 - acc: 0.9205 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19712/24857 [======================>.......] - ETA: 6:58 - loss: 0.2284 - acc: 0.9205 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "19776/24857 [======================>.......] - ETA: 6:53 - loss: 0.2282 - acc: 0.9206 - LRFinder: val_loss: 0.7263 - lr = 0.00807192 \n",
      "19840/24857 [======================>.......] - ETA: 6:47 - loss: 0.2280 - acc: 0.9207 - LRFinder: val_loss: 0.6558 - lr = 0.00846543 \n",
      "19904/24857 [=======================>......] - ETA: 6:42 - loss: 0.2277 - acc: 0.9208 - LRFinder: val_loss: 0.7199 - lr = 0.00887811 \n",
      "19968/24857 [=======================>......] - ETA: 6:37 - loss: 0.2274 - acc: 0.9209 - LRFinder: val_loss: 0.6923 - lr = 0.00931092 \n",
      "20032/24857 [=======================>......] - ETA: 6:32 - loss: 0.2272 - acc: 0.9210 - LRFinder: val_loss: 0.6125 - lr = 0.00976482 \n",
      "20096/24857 [=======================>......] - ETA: 6:27 - loss: 0.2269 - acc: 0.9211 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20160/24857 [=======================>......] - ETA: 6:21 - loss: 0.2266 - acc: 0.9213 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20224/24857 [=======================>......] - ETA: 6:16 - loss: 0.2264 - acc: 0.9213 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20288/24857 [=======================>......] - ETA: 6:11 - loss: 0.2263 - acc: 0.9214 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20352/24857 [=======================>......] - ETA: 6:06 - loss: 0.2260 - acc: 0.9215 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20416/24857 [=======================>......] - ETA: 6:01 - loss: 0.2258 - acc: 0.9216 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20480/24857 [=======================>......] - ETA: 5:55 - loss: 0.2256 - acc: 0.9217 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20544/24857 [=======================>......] - ETA: 5:50 - loss: 0.2253 - acc: 0.9218 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20608/24857 [=======================>......] - ETA: 5:45 - loss: 0.2251 - acc: 0.9219 - LRFinder: val_loss: 0.7117 - lr = 0.01024085 \n",
      "20672/24857 [=======================>......] - ETA: 5:40 - loss: 0.2249 - acc: 0.9219 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20736/24857 [========================>.....] - ETA: 5:34 - loss: 0.2246 - acc: 0.9220 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20800/24857 [========================>.....] - ETA: 5:29 - loss: 0.2245 - acc: 0.9221 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20864/24857 [========================>.....] - ETA: 5:24 - loss: 0.2243 - acc: 0.9222 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20928/24857 [========================>.....] - ETA: 5:19 - loss: 0.2240 - acc: 0.9223 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "20992/24857 [========================>.....] - ETA: 5:14 - loss: 0.2238 - acc: 0.9224 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21056/24857 [========================>.....] - ETA: 5:08 - loss: 0.2236 - acc: 0.9224 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21120/24857 [========================>.....] - ETA: 5:03 - loss: 0.2233 - acc: 0.9226 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21184/24857 [========================>.....] - ETA: 4:58 - loss: 0.2231 - acc: 0.9226 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21248/24857 [========================>.....] - ETA: 4:53 - loss: 0.2230 - acc: 0.9227 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21312/24857 [========================>.....] - ETA: 4:48 - loss: 0.2227 - acc: 0.9228 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21376/24857 [========================>.....] - ETA: 4:42 - loss: 0.2225 - acc: 0.9229 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21440/24857 [========================>.....] - ETA: 4:37 - loss: 0.2223 - acc: 0.9230 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21504/24857 [========================>.....] - ETA: 4:32 - loss: 0.2221 - acc: 0.9230 - LRFinder: val_loss: 0.7175 - lr = 0.01074009 \n",
      "21568/24857 [=========================>....] - ETA: 4:27 - loss: 0.2219 - acc: 0.9231 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21632/24857 [=========================>....] - ETA: 4:22 - loss: 0.2217 - acc: 0.9232 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21696/24857 [=========================>....] - ETA: 4:16 - loss: 0.2215 - acc: 0.9233 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21760/24857 [=========================>....] - ETA: 4:11 - loss: 0.2213 - acc: 0.9233 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21824/24857 [=========================>....] - ETA: 4:06 - loss: 0.2211 - acc: 0.9234 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21888/24857 [=========================>....] - ETA: 4:01 - loss: 0.2209 - acc: 0.9235 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "21952/24857 [=========================>....] - ETA: 3:56 - loss: 0.2206 - acc: 0.9236 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22016/24857 [=========================>....] - ETA: 3:50 - loss: 0.2204 - acc: 0.9237 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22080/24857 [=========================>....] - ETA: 3:45 - loss: 0.2202 - acc: 0.9237 - LRFinder: val_loss: 0.7574 - lr = 0.01126367 \n",
      "22144/24857 [=========================>....] - ETA: 3:40 - loss: 0.2201 - acc: 0.9238 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22208/24857 [=========================>....] - ETA: 3:35 - loss: 0.2199 - acc: 0.9239 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22272/24857 [=========================>....] - ETA: 3:30 - loss: 0.2196 - acc: 0.9239 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22336/24857 [=========================>....] - ETA: 3:24 - loss: 0.2195 - acc: 0.9240 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22400/24857 [==========================>...] - ETA: 3:19 - loss: 0.2193 - acc: 0.9241 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22464/24857 [==========================>...] - ETA: 3:14 - loss: 0.2190 - acc: 0.9242 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22528/24857 [==========================>...] - ETA: 3:09 - loss: 0.2188 - acc: 0.9242 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22592/24857 [==========================>...] - ETA: 3:03 - loss: 0.2187 - acc: 0.9243 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22656/24857 [==========================>...] - ETA: 2:58 - loss: 0.2184 - acc: 0.9244 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22720/24857 [==========================>...] - ETA: 2:53 - loss: 0.2183 - acc: 0.9245 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22784/24857 [==========================>...] - ETA: 2:48 - loss: 0.2181 - acc: 0.9245 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22848/24857 [==========================>...] - ETA: 2:43 - loss: 0.2179 - acc: 0.9246 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22912/24857 [==========================>...] - ETA: 2:37 - loss: 0.2177 - acc: 0.9247 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "22976/24857 [==========================>...] - ETA: 2:32 - loss: 0.2175 - acc: 0.9247 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23040/24857 [==========================>...] - ETA: 2:27 - loss: 0.2173 - acc: 0.9248 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23104/24857 [==========================>...] - ETA: 2:22 - loss: 0.2171 - acc: 0.9249 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23168/24857 [==========================>...] - ETA: 2:17 - loss: 0.2169 - acc: 0.9250 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23232/24857 [===========================>..] - ETA: 2:11 - loss: 0.2167 - acc: 0.9250 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23296/24857 [===========================>..] - ETA: 2:06 - loss: 0.2166 - acc: 0.9251 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23360/24857 [===========================>..] - ETA: 2:01 - loss: 0.2164 - acc: 0.9252 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23424/24857 [===========================>..] - ETA: 1:56 - loss: 0.2162 - acc: 0.9252 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23488/24857 [===========================>..] - ETA: 1:51 - loss: 0.2159 - acc: 0.9253 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23552/24857 [===========================>..] - ETA: 1:45 - loss: 0.2158 - acc: 0.9254 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23616/24857 [===========================>..] - ETA: 1:40 - loss: 0.2156 - acc: 0.9255 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23680/24857 [===========================>..] - ETA: 1:35 - loss: 0.2154 - acc: 0.9255 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23744/24857 [===========================>..] - ETA: 1:30 - loss: 0.2152 - acc: 0.9256 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23808/24857 [===========================>..] - ETA: 1:25 - loss: 0.2151 - acc: 0.9257 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23872/24857 [===========================>..] - ETA: 1:19 - loss: 0.2149 - acc: 0.9257 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "23936/24857 [===========================>..] - ETA: 1:14 - loss: 0.2147 - acc: 0.9258 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "24000/24857 [===========================>..] - ETA: 1:09 - loss: 0.2145 - acc: 0.9259 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "24064/24857 [============================>.] - ETA: 1:04 - loss: 0.2144 - acc: 0.9259 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "24128/24857 [============================>.] - ETA: 59s - loss: 0.2141 - acc: 0.9260  - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "24192/24857 [============================>.] - ETA: 54s - loss: 0.2140 - acc: 0.9261 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "24256/24857 [============================>.] - ETA: 48s - loss: 0.2138 - acc: 0.9261 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "24320/24857 [============================>.] - ETA: 43s - loss: 0.2136 - acc: 0.9262 - LRFinder: val_loss: 0.6765 - lr = 0.01181277 \n",
      "24384/24857 [============================>.] - ETA: 38s - loss: 0.2135 - acc: 0.9263 - LRFinder: val_loss: 0.6623 - lr = 0.01238864 \n",
      "24448/24857 [============================>.] - ETA: 33s - loss: 0.2133 - acc: 0.9263 - LRFinder: val_loss: 0.5818 - lr = 0.01299258 \n",
      "24512/24857 [============================>.] - ETA: 28s - loss: 0.2131 - acc: 0.9264 - LRFinder: val_loss: 0.7306 - lr = 0.01362596 \n",
      "24576/24857 [============================>.] - ETA: 22s - loss: 0.2129 - acc: 0.9264 - LRFinder: Skipping iteration since loss is 4 times as large as best loss (0.1898)\n",
      "24640/24857 [============================>.] - ETA: 17s - loss: 0.2128 - acc: 0.9265 - LRFinder: val_loss: 0.6890 - lr = 0.01429022 \n",
      "24704/24857 [============================>.] - ETA: 12s - loss: 0.2126 - acc: 0.9266 - LRFinder: val_loss: 0.4283 - lr = 0.01498687 \n",
      "24768/24857 [============================>.] - ETA: 7s - loss: 0.2125 - acc: 0.9266  - LRFinder: val_loss: 0.4033 - lr = 0.01571747 \n",
      "24832/24857 [============================>.] - ETA: 2s - loss: 0.2123 - acc: 0.9267 - LRFinder: val_loss: 0.4809 - lr = 0.01648369 \n",
      " - LRFinder: val_loss: 0.6442 - lr = 0.01728727 \n",
      "24857/24857 [==============================] - 2048s 82ms/step - loss: 0.2123 - acc: 0.9267 - val_loss: 0.6406 - val_acc: 0.8556\n",
      "\tLR Finder : Saved the losses and learning rate values in path : {.}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b4a278588>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clr import LRFinder\n",
    "\n",
    "num_samples = len(x_train)\n",
    "batch_size = 32 * 2\n",
    "minimum_lr = 1e-6\n",
    "maximum_lr = 100.\n",
    "lr_callback = LRFinder(num_samples, batch_size,\n",
    "                       minimum_lr, maximum_lr,\n",
    "                       validation_data=(x_valid, y_valid),  # use the validation data for losses\n",
    "                       validation_sample_rate=20,\n",
    "                       verbose=True,\n",
    "                       lr_scale='exp', save_dir='.')\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc'])\n",
    "\n",
    "# Ensure that number of epochs = 1 when calling fit()\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=batch_size, \n",
    "          validation_data=(x_valid, y_valid), callbacks=[lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_callback.plot_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6215, 299, 299, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6215, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/5 *2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
