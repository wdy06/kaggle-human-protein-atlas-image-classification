{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/opt/conda/lib/python36.zip', '/opt/conda/lib/python3.6', '/opt/conda/lib/python3.6/lib-dynload', '/opt/conda/lib/python3.6/site-packages', '/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg', '/opt/conda/lib/python3.6/site-packages/IPython/extensions', '/home/yukimiki/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sys.path.append(\"/tmp/fastai/old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(seed=32)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import scipy.optimize as opt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "#from torchvision.transforms import RandomHorizontalFlip, RandomVerticalFlip\n",
    "from tensorboard_cb import TensorboardLogger\n",
    "import torch\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed_all(7)\n",
    "import utils_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = 20   #number of workers for data loader\n",
    "arch = resnet34 #specify target architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = list({f[:36] for f in os.listdir(utils_pytorch.TRAIN)})\n",
    "test_names = list({f[:36] for f in os.listdir(utils_pytorch.TEST)})\n",
    "# tr_n, val_n = train_test_split(train_names, test_size=0.1, random_state=42)\n",
    "\n",
    "data_info = pd.read_csv(utils_pytorch.LABELS)\n",
    "tr_n, val_n = train_test_split(data_info, test_size = 0.1, \n",
    "                 stratify = data_info['Target'].map(lambda x: x[:3] if '27' not in x else '0'), random_state=42)\n",
    "tr_n = tr_n['Id'].tolist()\n",
    "val_n = val_n['Id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    #data augmentation\n",
    "    aug_tfms = [RandomRotate(45, tfm_y=TfmType.NO),\n",
    "                RandomFlip(),\n",
    "                RandomDihedral(tfm_y=TfmType.NO),\n",
    "                RandomLighting(0.05, 0.05, tfm_y=TfmType.NO)]\n",
    "    #mean and std in of each channel in the train set\n",
    "    #stats = A([0.08069, 0.05258, 0.05487, 0.08282], [0.13704, 0.10145, 0.15313, 0.13814])\n",
    "    stats = A([0.0868 , 0.05959, 0.06522, 0.08891], [0.13044, 0.09792, 0.14862, 0.13281])\n",
    "    tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n",
    "                aug_tfms=aug_tfms)\n",
    "    ds = ImageData.get_ds(utils_pytorch.pdFilesDataset, (tr_n[:-(len(tr_n)%bs)],utils_pytorch.TRAIN), \n",
    "                (val_n,utils_pytorch.TRAIN), tfms, test=(test_names,utils_pytorch.TEST))\n",
    "    md = ImageData(utils_pytorch.PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 512 #image size\n",
    "bs = 64  #batch size\n",
    "\n",
    "# dir_name = datetime.strftime(datetime.now(), '%Y%m%d%H%M%S')\n",
    "# print(dir_name)\n",
    "# dir_path = os.path.join('test', dir_name)\n",
    "best_model_path = '20181126233446best_resnet'\n",
    "\n",
    "\n",
    "md = get_data(sz,bs)\n",
    "learner = utils_pytorch.ConvLearner.pretrained(arch, md, ps=0.5) #dropout 50%\n",
    "#pretrained_model_name = '20181124135324best_resnet' # 299\n",
    "# pretrained_model_name = '20181125052614best_resnet' # 512\n",
    "# learner.load(pretrained_model_name)\n",
    "learner.load(best_model_path)\n",
    "learner.set_data(md)\n",
    "\n",
    "learner.opt_fn = optim.Adam\n",
    "learner.clip = 1.0 #gradient clipping\n",
    "learner.crit = utils_pytorch.FocalLoss()\n",
    "learner.metrics = [utils_pytorch.acc, utils_pytorch.f1_torch]\n",
    "# tb_logger = TensorboardLogger(learner.model, md, dir_path, metrics_names=['acc', 'f1'])\n",
    "#save_best_model = SaveBestModel(model=learner.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def sigmoid_np(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "preds,y = learner.TTA(n_aug=2)\n",
    "preds = np.stack(preds, axis=-1)\n",
    "preds = sigmoid_np(preds)\n",
    "pred = preds.max(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_soft(preds,targs,th=0.5,d=50.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    targs = targs.astype(np.float)\n",
    "    score = 2.0*(preds*targs).sum(axis=0)/((preds+targs).sum(axis=0) + 1e-6)\n",
    "    return score\n",
    "\n",
    "def fit_val(x,y):\n",
    "    params = 0.5*np.ones(len(utils_pytorch.name_label_dict))\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((F1_soft(x,y,p) - 1.0,\n",
    "                                      wd*(p - 0.5)), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds:  [0.48691 0.50588 0.55193 0.49488 0.48837 0.49975 0.46869 0.51245 0.54558 0.54873 0.52745 0.54202 0.51239\n",
      " 0.52313 0.51618 0.55023 0.51978 0.44676 0.43681 0.45921 0.49483 0.4693  0.42854 0.53179 0.4532  0.4644\n",
      " 0.53405 0.22686]\n",
      "F1 macro:  0.7034476503267851\n",
      "F1 macro (th = 0.5):  0.6697478780369277\n",
      "F1 micro:  0.7726512543039844\n"
     ]
    }
   ],
   "source": [
    "th = fit_val(pred,y)\n",
    "th[th<0.1] = 0.1\n",
    "print('Thresholds: ',th)\n",
    "print('F1 macro: ',f1_score(y, pred>th, average='macro'))\n",
    "print('F1 macro (th = 0.5): ',f1_score(y, pred>0.5, average='macro'))\n",
    "print('F1 micro: ',f1_score(y, pred>th, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fractions:  [0.46107 0.03604 0.10103 0.04247 0.05245 0.06338 0.02477 0.07819 0.00161 0.00129 0.00097 0.03089 0.01866\n",
      " 0.00837 0.03411 0.00032 0.00676 0.00676 0.02896 0.04537 0.0029  0.13417 0.02606 0.0888  0.0119  0.32497\n",
      " 0.00772 0.00129]\n",
      "Fractions (true):  [0.42535 0.03861 0.11776 0.04923 0.05856 0.07497 0.03185 0.08784 0.00129 0.00161 0.00097 0.03539 0.0222\n",
      " 0.01544 0.03636 0.00064 0.01673 0.00804 0.03024 0.04698 0.00547 0.12323 0.02574 0.09299 0.0103  0.26062\n",
      " 0.01062 0.00032]\n"
     ]
    }
   ],
   "source": [
    "print('Fractions: ',(pred > th).mean(axis=0))\n",
    "print('Fractions (true): ',(y > th).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_t,y_t = learner.TTA(n_aug=2,is_test=True)\n",
    "preds_t = np.stack(preds_t, axis=-1)\n",
    "preds_t = sigmoid_np(preds_t)\n",
    "pred_t = preds_t.max(axis=-1) #max works better for F1 macro score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pred(pred, th=0.5, fname='protein_classification.csv'):\n",
    "    pred_list = []\n",
    "    for line in pred:\n",
    "        s = ' '.join(list([str(i) for i in np.nonzero(line>th)[0]]))\n",
    "        pred_list.append(s)\n",
    "        \n",
    "    sample_df = pd.read_csv(utils_pytorch.SAMPLE)\n",
    "    sample_list = list(sample_df.Id)\n",
    "    pred_dic = dict((key, value) for (key, value) \n",
    "                in zip(learner.data.test_ds.fnames,pred_list))\n",
    "    pred_list_cor = [pred_dic[id] for id in sample_list]\n",
    "    df = pd.DataFrame({'Id':sample_list,'Predicted':pred_list_cor})\n",
    "    df.to_csv(os.path.join('logs', dir_path, fname), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_t = np.array([0.565,0.39,0.55,0.345,0.33,0.39,0.33,0.45,0.38,0.39,\n",
    "               0.34,0.42,0.31,0.38,0.49,0.50,0.38,0.43,0.46,0.40,\n",
    "               0.39,0.505,0.37,0.47,0.41,0.545,0.32,0.1])\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "save_pred(pred_t,th_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Thresholds: ',th_t)\n",
    "print('F1 macro: ',f1_score(y, pred>th_t, average='macro'))\n",
    "print('F1 macro (th = 0.5): ',f1_score(y, pred>0.5, average='macro'))\n",
    "print('F1 micro: ',f1_score(y, pred>th_t, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_prob = [\n",
    " 0.362397820,0.043841336,0.075268817,0.059322034,0.075268817,\n",
    " 0.075268817,0.043841336,0.075268817,0.010000000,0.010000000,\n",
    " 0.010000000,0.043841336,0.043841336,0.014198783,0.043841336,\n",
    " 0.010000000,0.028806584,0.014198783,0.028806584,0.059322034,\n",
    " 0.010000000,0.126126126,0.028806584,0.075268817,0.010000000,\n",
    " 0.222493880,0.028806584,0.010000000]\n",
    "# I replaced 0 by 0.01 since there may be a rounding error leading to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_soft(preds,th=0.5,d=50.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    return preds.mean(axis=0)\n",
    "\n",
    "def fit_test(x,y):\n",
    "    params = 0.5*np.ones(len(utils_pytorch.name_label_dict))\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((Count_soft(x,p) - y,\n",
    "                                      wd*(p - 0.5)), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_t = fit_test(pred_t,lb_prob)\n",
    "th_t[th_t<0.1] = 0.1\n",
    "print('Thresholds: ',th_t)\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "print('Fractions (th = 0.5): ',(pred_t > 0.5).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Thresholds: ',th_t)\n",
    "print('F1 macro: ',f1_score(y, pred>th_t, average='macro'))\n",
    "print('F1 macro (th = 0.5): ',f1_score(y, pred>0.5, average='macro'))\n",
    "print('F1 micro: ',f1_score(y, pred>th_t, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred(pred_t,th_t,'protein_classification_f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred(pred_t,th,'protein_classification_v.csv')\n",
    "save_pred(pred_t,0.5,'protein_classification_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [8,9,10,15,20,24,27]\n",
    "for i in class_list:\n",
    "    th_t[i] = th[i]\n",
    "save_pred(pred_t,th_t,'protein_classification_c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(utils_pytorch.LABELS).set_index('Id')\n",
    "label_count = np.zeros(len(utils_pytorch.name_label_dict))\n",
    "for label in labels['Target']:\n",
    "    l = [int(i) for i in label.split()]\n",
    "    label_count += np.eye(len(utils_pytorch.name_label_dict))[l].sum(axis=0)\n",
    "label_fraction = label_count.astype(np.float)/len(labels)\n",
    "label_count, label_fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_t = fit_test(pred_t,label_fraction)\n",
    "th_t[th_t<0.05] = 0.05\n",
    "print('Thresholds: ',th_t)\n",
    "print('Fractions: ',(pred_t > th_t).mean(axis=0))\n",
    "save_pred(pred_t,th_t,'protein_classification_t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Thresholds: ',th_t)\n",
    "print('F1 macro: ',f1_score(y, pred>th_t, average='macro'))\n",
    "print('F1 macro (th = 0.5): ',f1_score(y, pred>0.5, average='macro'))\n",
    "print('F1 micro: ',f1_score(y, pred>th_t, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
